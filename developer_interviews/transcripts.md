# Anonymized Interview Transcripts

## P2

When I commit the lockfile into the repository, I typically expect all the dependencies to be exactly the way that I have it set up. And I expect very minimal breakage. I'm going like, if I, you know, if I check out a commit from six months ago, and I try to try to build it and run it, I expect it to work. And with a lockfile, like it almost always does. So it allows me to essentially step back in time and see like, all of the dependencies and all of the sub dependencies and everything. It allows me to make sure that it's essentially like a snapshot. Like if I set up like a Docker image for every single commit, it allows me to like emulate that. Like I'm 100% certain that it's going to be identical no matter when I go back to it. So, yeah. I don't normally look at it. I just add it to the commit and I push it. 


I'm kind of the only like real maintainer. Other people for sure contribute and I, you know, pull those in. But I'm working on it alone, like day to day. So I'm typically not like trampling over anyone else's changes when I commit my lockfile changes. But if I was working with others in a professional capacity where I was working with other people, I would want it to be sort of expected behavior that everyone commits it at the same time as you commit the other change to like the toml file when you're changing the, like if you change the version or you add a new dependency, I expect that to be in the same commit as the lockfile change. And so then it's much easier to deal with merge conflicts. As of right now, there's no real like procedure because it's sort of just me working on it. So there's no like conflicts. But if there were others, it would be it would be pretty easy to make sure that that didn't cause any problems as long as everyone made sure to commit it. And like we all follow that behavior. 

Default, I'd say would be to just run the cargo add command, which will put the latest version of it. There will be some cases in which I have to pin it to a specific older version because the newer version has breaking changes that I haven't had the chance to sort of patch up and things like that. But most of the time I don't, I rarely edit the toml file directly. I'm running things like cargo add and then like adding features with that command. Just because when I'm at, if I were to like type in a dependency, I wouldn't typically know what version I want. I just want like the last version. So I use the command to edit the toml file. 

I typically run cargo tree and then I just search in the output there. I'm not, I've, now that you mentioned it, it's probably better to look at the lockfile just so that you can see like all of them at once instead of having to scroll through the output. But when I do it, I usually just do cargo tree to see which, it allows me to see which dependency is a dependency of which dependency. Like sometimes multiple versions will exist, like one pack, one dependency uses one version and another dependency uses another. And I'd like to say like, okay, I want to get rid of the one that uses the older one or update it. And the lockfile, as far as I know, doesn't tell me like who wants this package. Or if it does, it's not as easy to parse as just like the tree command. So I typically use cargo tree. 


Typically what I will do is I will recreate the, I'll pull their change into a branch. I will recreate the change that they did to the cargo of toml and then see if my lockfile changed in the exact same way. Just because often I don't know exactly if this should be a dependency of that. But if when I add it, it adds another dependency. You know, if I add X and it adds Y and they added X and it added Y, you know, then it matches and that's okay. I don't typically vet every dependency that I get PR for. But when I do get a new dependency, I want to make sure that like nothing is sneaking into the lockfile. I'm not, I'm not even sure if there's an attack vector there, if like downloading a dependency will necessarily cause any problems. But I will make sure that the change to the lockfile is identical to the change that was caused by the change in the toml file. 

So typically what I do in the CI CD pipeline is it builds and does a release on the CI CD from the latest commit. So it will use the latest lockfile. None of my CI CD's sort of install it from cargo. Like they don't run cargo install. They typically build and run the cached version of it. And also like users, almost every, I'm pretty sure almost every user uses the Docker image that I put out. And I personally think that that's a much better, much better distribution mechanism just because most people are using it in a server capacity. So Docker is just like naturally better for that. I'm sure there are some people who do cargo install. And for the most part, even if you ran cargo update, it wouldn't cause any breaking changes. I make sure that running cargo update, I run cargo update every once in a while. But even if you did that without locked, I'm fairly certain that it will still work just fine. Because if there's something that I need to hold back, I define it to be held back in the toml file. And so it still holds without the lock file being checked in. 

Definitely. I do a lot of cargo tree, which parses a lock file. I do that to make sure that dependencies, if there's like a really heavy dependency, I can make sure to find a lighter alternative. But also just to see what versions it's pulling in. Cargo update, of course. Cargo add and remove. Yeah. That's about it. The rest of it I do manually with like things like features and stuff. That I edit by hand. But mostly those few, yeah. 

I've had no problems with the cargo lockfile. It's all worked exactly how I expect it to. 

I mean, outside of the fact that certain dependencies will break things and older ones will, you know, either work or not work depending. I don't think there's been any problems that were like caused by the dependency system in cargo. Yeah, it's all pretty, it's well built to like match my needs. If I need to set my dependency maximum to a certain amount, like I don't want to go higher than this. I use the equals, you know, things like that. But there's been problems that I've had pretty frequently actually with hyper. It's on like version one at least, but we're stuck on 0.14. And so I need to make sure that like all of the dependencies don't go past that. But that's pretty easy to specify. I just say hyper equals 0.14. So I haven't had any problems with dependency management itself. There's been problems with dependencies. But like that isn't the dependency management within cargo. I've had no problems with that. It's all working basically perfectly. I haven't had to think about it much. 


I think that this isn't relevant to me necessarily because I commit the lock file. But I know that in some cases if you don't commit the lock file and a dependency gets yanked, you cannot build it anymore. Because it may exist to people who have the lock file. If you have the lock file, you can always build it, even if it's yanked. But if you don't have a lock file and it gets yanked, you cannot under any circumstances build it. And it's to me, I think that that's the that's a huge oversight that like it's purely just cargo telling you you can't do it. There have been people who like patched out the three lines that check that stuff. And they're like, okay, I can build it now. Like what's now that I have a working lock file, I can, you know, go back to using regular cargo. But like to me, if I didn't commit the lock file for some reason, and I had an old version of a dependency yanked, that would be really frustrating to me to be unable to build it. And that seems kind of like not along with the rest of Rust sort of dependency management. And that's not just like a like yanking dependencies is not uncommon. There is the really core dependency of Ring, which is like a very, very common cryptography library that was maintained for a while. And they had a they had a policy that they would yank the every time they released a new one, they would yank the previous one. So there would always be constant broken versions of things and people have to patch out the lock file and things like that. And it was they changed the policy of that package. But like the root problem still exists that if dependencies yanked and you don't have a lock file, you know, you can't do anything about it. You can't build it. You have to figure out a way to like wrangle it to let you do what you want to do. Maybe that's not relevant because that implies that you don't have a lock file. But I think that, yeah, I think that that would be one problem that like I have run into outside of this project. 

I do not personally use Nix. It was a PR that someone added so that it could be added to I guess Nix is equivalent packaging system. But I have heard of it, Nix, and it looks really cool. I just haven't done the work to like actually adopt it myself. 

## P3

This interview was conducted over coffee for about an hour. The conversation was not recorded. Only written notes were taken.

Challenges when managing dependencies
The dependencies get unmaintained - no bug/vulnerability fixes
When the organization responsible for maintaining the dependency get acquired by another company 
Complex coordination problems 
Several versions of the same dependency  
Security of the dependencies
Sanity check - when bumping dependencies existing tools are not good enough recognizing the malicious updates
When a dependency has released only the binary to improve the compile time - nobody cares about verifying the maliciousness 

The reasons for not using lockfiles
As bevy is a game engine, on consumer side using a lockfile can cause difficulties
Better user experience is more important than the developer experience 
Cargo cache mechanisms are buggy, therefore, not caching is the standard
Automated frequent dependency updates are more important than reproducibility

Other tools used to support dependency management
Cargo semantic version violations checkers
Cargo tree to visualize the transitive dependencies

Suggestions to improve dependency management processes
Use only trusted package repositories when shipping binaries
Verify that the checksum of the code on github matches the code on crate.io 
Socio technical solutions
Shared partial maintainship of dependencies 
Verify the reliability of the package by verifying the maintainers of it
Have a mechanism of secret sharing or shared keys between the maintainers of a dependency
Bypass crates.io have a trusted managers

## P6

I don't manually check it unless I'm reconciling it, unless someone is contributing a package change. So, then I'll look at it and see, because sometimes there will be artifacts from their operating system, and I need to make sure that it was installed correctly, too. Because, you know, maybe it's different project to project, but in my specific project, you need to make sure to install it in specific folders and things like this. 

Yeah, I'm going to take a look at one right now. So, mainly the version, and I'll look at what the resolution link is. Sometimes there's, I forget what exactly it's called, but whether something is marked as dev, if it was correctly installed as a dev dependency. 

Yeah, I use some of the NPM scripts. Like, you can run NPM ls and then write the package specifically. Specifically, I guess it sort of is part of my debugging process, but not so much of me looking at the file, but seeing if everything is still running correctly, like the installation process. Like a verification, but not exactly as a debug.


Yeah, there was a time where I, so, there's one specific package called the rollup, and that's a very common web compiler type of package. And it's, once in a while there, there'll be some very specific, hard to debug problems with that package. And I needed to manually, I was trying to install a specific version, but I was running all the installation scripts, and it still wasn't installing the one I wanted. And so, I kind of manually had to change each link. It was, I don't know if it's a, I don't know if that's a common thing people do, but in that case, I needed to do it. 

Yeah, I don't, I don't think I've ever deeply looked at it. Um, I'm, I mean, I'm sure it's used in the automatic process of installing and all this, but, uh, I, I personally, if I have benefited from it, it's been indirectly. I haven't paid careful attention to it myself. 

Yeah, so I'll manually update the version on there of the app. Um, but really it, it only gets changed, um, uh, with, with package updates. So , um, once, once in blue moon, I'll, I'll have to rebuild the package lock, uh, lock file, like in case I'm having trouble installing something, like, and just compare differences that way. But I, I would say those are the only times. 

Well, it's, so when, well, either when we install a new package or update the version of an existing package, Or even, um, or even as a result of a security advisory, you know, npm has this automatic process for that. So... Yeah, or do it. Okay. Um, so those, those are really the only times, and just manually updating the version of my app, um, at the very top. 

Yeah, yeah. I do enforce, um, uh, adhering to the package lock file. Um, we use npm-ci for all the CICD. That's very important because, um, I even have specific tests that run in a Windows environment, for example, as opposed to, like, normally it's just running on Linux. Um, because certain, certain dependencies wouldn't resolve correctly if, if we didn't enforce it. 

Yeah. Yeah. I, you know, I ran into a situation where it wasn't work, my app wasn't working for Windows users and that's why there's that workflow now. Uh-huh. Um, and early on in the project too, we were trying to set up end-to-end testing automatically with Playwright. And, and someone had contributed that workflow. Um, and it worked for them locally. And I saw that they were using npm install instead of npm-ci. So, um, that's one specific situation where I saw, oh, it's, doesn't seem to be working in, in GitHub servers for some reason. And, and, and that was part of the debugging process. You know, it really, it helped us realize, you know, what was going on. 

Yeah, so I, I, I use the npm cache clean. Um, basically anytime I'm testing the app in general, I actually wipe, I have a script that wipes the node modules folder and runs a clean installation that way, cleans the cache, and then does npm-ci. And that's, that's the, the true and tested way of getting a, a, a clean copy of the app every time. So, uh, it's just built into even my development workflow. 


Yeah. I mean, um, just working across different operating systems, um, you know, also on macOS. I've had issues where deleting, like doing that same process, um, deleting the node modules folder created issues with npm and then nothing would install. Um, and just, I've, I've had a lot more issues, I think, with also just the installation process sometimes, like hanging, um, for whatever reason, or not resolving dependencies. Um, so there, so there have been, I think the most common issues I've had are OS related, like I was on Windows or I was on macOS versus Linux, or some kind of connection issue with the, with npm that messed it up along, along the way. 

Yeah, that's, that's a hard one. I would say, uh, it's, it's hard because sometimes, um, I, like some of the things that I think they have built into it, that wasn't always there have been helpful, like, like being able to override package, the package lockfile. Um, like on the package JSON file, you can set it in an overrides field and it can say exactly, uh, which version the lockfile should use. Um, that's, that's been helpful in certain situations. Um, maybe an understanding of, of how it constructs the lockfile. Cause it's still kind of a mystery to me. Um, and, and maybe some way, uh, um, and NPM does, does a good job of this already, but maybe some way to not just security vulnerabilities, but maybe issuing warnings with specific problems that are happening with packages. Like maybe, maybe the package maintainer can, can issue a warning, like certain users are having trouble on this specific environment or whatever it is. Maybe some kind of feature like that. Um, I don't know if that's related to the lock file construction itself, but I, I know it's, I mean, some, it's, some of these issues I've had with it are just so hard to debug. And, uh, until I do some very thorough digging of what's going on. Um, so anything to help with that, I think would be appreciated. 

Yeah. I mean, I've, I guess I've, I've had situations where I could look back in my Git history and see, okay, well, this package was working, um, when the lock file looked like this. And for some reason, when I rebuilt the package lock file, um, later on, it wasn't working anymore. So, uh, that was one time I literally manually copy, copy pasted. I went exactly where, um, that package, how that was resolved before and it was working and I literally replaced it. And so, okay, like it needs to be this version. Um, yeah. So in that case, you actually, um, enforce the, uh, look for in your GitHub backhands, right? So that's, that's why you had to copy it and then it was resolved. 

Um, yeah, the ideas and. Yeah. Um, I think, uh, I think it's interesting to see new, uh, new, like JavaScript environments that kind of have their own, uh, package resolution strategies. Like, like the bun runtime is pretty interesting too. That also has like some kind of lock file. Um, so I think, I think NPM is still great. And I think maybe it could learn from these other, uh, uh, these other runtimes or, or services like, uh, you know, and JSR is another one that's new. 

Yeah, I, I, I kind of, um, I still mostly build with NPM, but I use, I, I also layer Bun on top of that. So I, I like to use NPM as, as the, the source, so to speak, like the, the base. And I try to build things that work for sure in an NPM environment and then go with Bun from there to like benefit from increased runtime speeds and things like that.  


Yeah. It, it depends how much changes the contributors is, is, uh, is pushing. And, and I am really careful with that to make sure that, um, that there aren't any merge conflicts in the package lock file because it can be, it can get very messy. And there, there, there have been times where I, um, um, it's mainly, uh, maintaining the repository, like the main repository itself. It's not usually a problem. But I have, um, I have helped people maintain forks of my project where they install, you know, like their own dependencies and things like this. That aren't in the main project. And so there, it's more of an issue because you have completely divergent packages. And usually if something is too much to reconcile, like, like I, I, I have a pretty decent computer and, and, and even like in trying to merge changes, like it's the Git, Git is kind of overloading and taking up a bunch of memory.  . And is even having trouble showing them all.  So in, in situations like that, I just, I just rebuild the package lock file and, and I test everything in the app and see if it's, if it's still functioning as expected. That's, it's, it's a bit of a destructive process, but, Yeah . But it, it, it usually helps me more than, more than hurts. 

Yeah, absolutely. Absolutely. I, I, I do care. Um, and so for the main repository, I almost never do that where I rebuild the whole package lock file. Um, and it, it's very important to keep it reproducible. Um, and for that reason, I also use, I, I also heavily rely on Docker to be like one of the number one ways people, um, are able to even use the project. Um, cause that way there's really one source of truth. Um, and I'll even host the image that Docker produces. Um, yeah. Um, and, um, uh, so even with, uh, so you, uh, rather like think that the Docker image would be your application inside the document would be more reproducible. 

Yeah. Um, well, mainly because I work on the, the project is so centered on GitHub. I use their, mainly a lot of their tools and, um, mainly that like they, they have a security section for the repo. And that also alerts me anytime I make pull requests. Um, that kind of scans the package lock file, um, automatically. 
P1

Yeah, it's committed. And I can give you a brief reason why I commit it. Because I'm using Rust for SnifNet. And as Rust suggested, the official guidebook suggests to commit files for executable and to not commit it for libraries. This is because usually for executables, you want to log to a specific version of each package to not break everything. Because basically, executables are only used by end users. Instead, I also maintain other Rust libraries. And in libraries, I don't commit it because, you know, libraries are used also in other projects, also in other libraries. So it's not a leaf dependency, but it's something used also by other developers. And usually to not break their dependencies, it's suggested to not commit it. But yeah, with SnifNet, I am because basically, it's a binary. 

Yeah, usually, to keep dependencies up to date, I use Dependabot on GitHub, that you probably already know. So basically, unless that, of course, when I add a new dependency, because I'm adding new features, I do it manually. But for updates, they are just submitted daily by Dependabot. And I just merge the pull request that is also updating the lockfile. there is also cargo update, of course, which I also use that. Yeah, so it's either via Dependabot or cargo update. 

No, I only check it if there is some problem, some conflict, you know, the dependency. But in normal scenarios, I don't check it because of course, it's supposed to be generated automatically. So if everything works, I think there is no real reason to check for it. So if you just ran into some kind of a problem with dependencies, like breaking updates or something. 

Yeah, I use both. But as I mentioned, this is the only case where I check it visually. Actually, it happened once that I had the dependency conflict. And this was due to two different dependencies using another dependency. And the way I solved it was just by restricting the features of one of the two dependencies. In Rust, every library has some features that can be enabled or disabled. But I didn't need all the features of one of the dependencies. So I had the set of features and I was able to solve it. But yeah, usually I check the lockfile. 

Yeah, because I don't trust anyone. Yeah. In practice, what I do is, of course, dependable. I just review toml the file, but usually it's just a version bump, so it's just a digit. But if there is some users and it happened that they had new dependencies in, not in the lockfile, but in the manifest, of course, the lockfile is updated as a consequence. But since I prefer to double check, I clone their fork locally, and I run card back date, so that I'm sure that the lockfile is reflected on the actual changes, and, you know, maybe they had something malicious, so it's better to check. 

Yeah, I just check if it's the same with git diff, yeah. 

Yeah. When I use in development, I don't use it, but it happened one time, a few months ago, that there was a library, one of my dependencies, that was updated as a minor version, and as you know, of course, minor versions usually don't break stuff, but in that case, it breaks stuff. So it wasn't a minor version, even if it was dogged as that. So basically, it was a same problem. Semantic versioning was not respected by them. And I got an issue by a guy that had some problem. So I updated the readme, and saying that if they download from cargo, they should use cargo install dash dash locked. Because in that way, I'm sure that they're using the dependency in the lockfile. Because otherwise, cargo as default tries to pull new versions, even with binaries. So even if you have pushed the lockfile, cargo still tries to, to ignore it. So you have to, to specify a lock in order to use it. 

No, I'm not forcing it because usually, I'm keeping the lockfile always up to date. So locking it doesn't make sense because it's always the last day latest version. 

Yeah, it was a problem that I mentioned before. Basically, there is this library that is a profanity check that I'm using because I'm parsing large external files. And I'm checking if the word contained in these files are not something weird, you know. So basically, they updated this library, pushing a minor version change that was updating the list of words to check against for profanity. And so this was a minor version, of course, but they updated the words and I got a fake positive. So it breaks something up. Yeah. But yeah, I think that in these cases, the situation can be solved by using the locked flag. 

I'm not sure. Maybe cargo clean when there is some problem. But yeah, I think that's it. 

Usually, it's because I did some error, but because the compiler is never wrong. So probably when something is not as expected, I retrace my tabs because I think that I did something wrong. So it's my fault, not the compiler. 

I've never actually checked checksums. I mean, the only times that I suspect is when someone else is updating my code. But again, I think it's enough to run cargo clean and cargo update. And so yeah, basically, I'm trusting cargo. And if there is an upstream problem in cargo, I get affected, of course, because I'm trusting, I'm relying on it. 

Yeah, I think that. Yeah, probably it'd be nice if the lock file was automatic in case of binaries. So if the cargo lock is published, I think that a good default might be to use it actually. Because the first time I didn't expect this behavior. And then reading the documentation, I found out that the cargo lock is ignored, even if it's present, even if it's present, if you're not using that flag. But other than that, I have no particular concern. 
P5

Generally not. We do not. We do not. There are very few cases where we need to. The reason why we have to do that is mostly because we need to investigate some deep dependencies that we might not be aware of. Again, it's mostly for security reasons, but we can use commands such as NPM list, which gives you the list of dependencies and that can explore relatively deep inside the dependency tree to see where the components are used, which ones are deduped and so on. So, but it's pretty rare. I mean, I don't know if you looked into it, but it's quite wide what you can find inside the package lock. So it's not really readable. 

No, we do not. We do not check the lock file. I would say most of the time, the reason why the lockfile would change is because of a security update. And we have some trusted tools, which does the right updates. So we do not have to investigate why the package lock has changed. So it's mostly because of security updates. 

There is no strict guidelines about when or how we should push the package lock. But as you mentioned, every time we have a new dependency to a project, first you modify the package.json, then you do an npm install, and then you have the package lock being updated. So you push that. What we try to do at SAP, at least, is, well, in my team, we try to minimize the content of a commit. So if we have to add a dependency, we will add the dependency, commit that, and then work on what we need to do. So we try to have small commits. Beside that, I mentioned that we have some security tools which are going over the list of dependencies. So those tools require access to the package lock. We recently had some troubles with the package lock. Because again, for security reasons, we try to keep up to date with the latest version of node. So as you may know, the package lock has, at least we are in version three now. So there are like three different, well, not really syntaxes, but three different versions of the package lock file. I know also that you can change the dependencies are either deduped or not through some configuration in the npmrc. But we don't do that. We just apply the defaults. So to answer your question, there is no strict guideline on when to push the package lock. But we try to do that in small commits, at least. We don't have a huge commit with lots of files plus the package lock. Otherwise, it's a bit confusing what has been done in this case. It's a bit confusing what has been done in this commit. 

There are many ways to answer your question. So first of all, we clearly distinguish the production dependencies from the development dependencies, which means you know in the package.json, you have two sections. Well, actually, you have three if you consider the peer dependencies, but we don't use peer dependencies. So the dependencies are the dependencies used only for development. So those dependencies should not be pushed to production. Typically. So what we do is we have a clear distinction between production dependencies and development dependencies. When we go through the pipeline in order to test or to run our tests, typically we use npm ci to install the dependencies without changing the package locks or by trusting the package lock. And also, since we are developing microservices, we have Docker files where we build the images and the image to be pushed onto the image to be pushed onto the GCP platform. So this Docker file also ensures that we grab the dependencies from the package lock by using several stages. And the first one is typically to use npmci to get the dependencies. I'm not sure I was clear. Sorry about that. 

Oh, well, I would say the most basic requirement is whatever is needed to run the production dependencies, obviously. But it's true that there are some knowledge that you have to be aware of. For instance, we use TypeScript. So TypeScript is a transpiler. So typically when we go to production, we don't need TypeScript anymore. Instead we just push the build result. So the dist folder or whatever you want to name it, which contains only JavaScript files. So typically TypeScript is a development dependencies. The same way, everything that is around linting, testing, what else? Some build tools also sometimes for Vue, for instance, we have VTest, we have VIT, which is a bundler to produce the application. So those kinds of stuff are development dependencies. But sometimes there is a thin line between a package that might be used both in production, but not everything is used for production. But since it's bundled in one package, we don't have the choice to just put it. So for that, we, from time to time, at least for the UI, we use tree shaking so that it reduces the dependencies. And we have something that we have something that is bundled that contains the whole JavaScript. So we don't have any more dependencies. So that's not a problem. But for services, typically we try to distinguish what is there from prod according to the fact that we put only what is required on prod. I hope I answered the question. 

I will be honest with you. I never looked into that. I know that some teams at SAP don't trust the official NPM registry. That's the way we name it. So we have a sort of clone owned by SAP, which is called Artifact Repository, something like that, where you can configure NPM to grab the packages from this registry. So it's like a trusted source of packages. But at least in my team, as of today, we rely fully on the public NPM. So we trust that the fact that the checksums are being validated, but we'd never really investigate that. We just trust the system. 

Yes, sure, sure. So we have a lot of security tools, obviously. So the first one is called Black Duck. So Black Duck, what it does, it takes what we call the bill of material for the package, so for the product, which is more or less the package lock. And Black Duck uses a list of vulnerabilities based on the package names, on their versions, on the reports on a regular basis on our products to know if one of the dependencies of this product is having a known vulnerability. So that's one thing which leverages the package lock.json. We also use Dependabot, which does that proactively. So Dependabot will also have its own list of vulnerabilities. And if it detects that one of your packages is vulnerable, it will automatically commit an update of the package lock, trigger the CICD. And if everything is good, we just merge automatically. And we just recently moved to Renovate. I don't know if you know it, but Renovate is also quite an impressive tool, very configurable. And that does almost the same thing. Just go over the list of packages and is capable of not only for vulnerabilities, but also to keep up to date with the latest version. Because if you're familiar with the topic, there are two main problems with dependencies. First, obviously, the security vulnerabilities, but also from a maintenance point of view. If you rely too much on an old package, then you have the risk that at some point this package is deprecated for whatever reason. And then you're stuck because you rely too much on this functionality. So we try to always stay up to date using those tools to make sure that we have the latest version being run in production.

well, I have a good example in mind actually, because one of our practices is to try to avoid the copy paste across the code everywhere. We built a library. So this library comes with its own package log.json. But we recently realized that when you embed the library in another project, the package log of this library doesn't necessarily influence the dependencies you will get in the project where you use this library. So I've read about, there is, I forgot the name about the file, but there is another file that is really similar to the package log, but that has a different name that you can publish with your library so that you can impose the dependencies. I forgot the name, but it's not named package log. So you can produce this file so that with the library comes a sort of fixed list of dependencies that you have to respect. So that's one thing that I observed recently, and we're looking into that. But because of renovate and everything, we're still up to date. So that's not a big problem. And another example I have in mind, I had some troubles with dedupes, for instance. It's sometimes happened that we have to use overwrites in the package lock.json. And I have to be honest, sometimes it's really difficult to understand how it works because it either works or not work. And you don't really know why, because there is no clear debugging tool to understand how this list of dependencies is being built and resolved by an NPM. So that's the two examples I have in mind. 

Well, I would say that one thing that could be interesting is, I'm pretty sure you've faced that, is whenever you have problems installing NPM packages. So it may happen from time to time that you have things like a package which declares a specific version of the engine or a specific version of Node.js or a specific version of NPM itself. And sometimes it breaks the installation. The error message that you get is really cryptic. Like, you really have to dig down the traces a lot to understand what's going wrong there. And I believe it's related to the complexity of what NPM does. But the problem is that when you're not too much into, I would say, if you don't necessarily understand precisely what's going on, you're completely lost. And I would say most of the time what people do is they delete the NodeModules folder, they delete the package lock, and then they retry and install. And then they see if it works. And if it doesn't work, then they change something in the package, they try again. So I would say troubleshooting NPM is probably the most complex things I've ever seen in Node.js environment. Well, there are other things which are complex, but related to what we're discussing. So hopefully, whenever it goes right, it's okay. It's a nice tool. But as soon as you've got a problem, it's a mess to figure out what's wrong. So deduping, overrides, things like that. It's really complex to understand how it works and how to make it work when you've got a problem. And that's really my pain. And hopefully, or luckily, it doesn't happen too often, I would say. 

## P7

So usually the issue with dependencies from what I experience is usually when I'm working in my local, it's working just well. But when I run in continuous integration, like GitHub actions or some... I don't know. There is error on the server and the continuous integration. So I think it's related to the dependencies. And usually I find what kind of dependencies is that. It's not... What's the difference with my local setup and the server.
 
Usually I just see the... what kind of error. And then from the error message, I just kind of search what this error means and which of the dependencies that trigger this error. So usually after... After finding some information, then updating the dependencies, one of the dependencies, can solve the issue. 

I'm not checking the lockfile manually. 

I prefer to just use the npm and then use specific tools to manage dependencies. 

Yes. It can be a... if the problem is in the... in one of the dependencies... I maybe... pin... pin... In npn there is a package JSON that we can pin a resolution... to the specific version of dependencies. So if the code is only running with the specific version, can be using the resolution. Yes, because in the lockfile, there are so many dependencies of the dependencies. And the dependencies, it's kind of too many. But in the package JSON, we can know which of our dependencies could be the problem. 

I don't usually check the integrity because in my opinion, it must be checked by the tools that I use. So I don't usually check the integrity. 

Yes. That's my concern as well. The reproducibility is because especially when committing a new version or committing specific tags, we have to make sure that our local setup will be the same as others. And the details of the dependencies, the version will be the same. So it will run the same as what we built here and what others built. So it's a must have, I think, to prevent what kind of problem that might be not because of our code, but it might be some of the dependencies from our code to prevent that kind of problem, I think.

Yeah. So, even in the local I usually use just npm install and at the npm build lockfile automatically. So, for the continuous integration, I'm using the npm ci. So, it's just pulling what it doesn't build again. So, it just run like usual. 

Maybe the versioning of the dependencies with current setup? I cannot know which version is the latest and how to automatically in update specific package that we want to put without mentioning it in package. But maybe some tools that can automatically update to the specific version. 

## P4

Not unknowingly. In Rust, many crates are under version 1.0, so semver allows breaking changes when bumping just the minor version. My personal feeling is that the Rust community takes semver seriously, and I'm looking forward to improved tooling like cargo-semver-checks.


This was the previous recommendation Should Cargo.lock be committed when the crate is both a rust library and an executable on StackOverflow, but has since changed. I have not revisitted this choice, but if I were to start a new project today, I would follow the latest recommendations and defaults.

Not in my past open source projects. My preference is to avoid dependencies as much as possible, so generally I don't run into issues by not using exact versions. In my work environment, we do use lockfiles, and they are valuable, as it ensures the dependencies' code doesn't change unwillingly. But it is also important to be mindful when updating the lockfiles, and changes to them should be reviewed as if it was any other part of the code.

cargo upgrade sporadically, but this also changes the Cargo.toml. Whenever I do `cargo update`, it is most likely an accident, and I meant to use the other command. I generally don't care about having exact versions when developing my open source projects, as long as the versions that get installed are compatible.

For open source work when I'm not committed to delivering strong promises, I pretend lockfiles don't exist or don't give them much thought. It is something that works transparently, so I don't dedicate much attention to them.

Cache invalidation is a big issue when using certain package managers in other languages when there is a need to work from multiple dependency repositories for security reasons, often requiring disregarding the previous lockfile and generating a clean one. But the impact of doing so is minimized due to lockfiles being reviewed.
When the existing lockfiles is deleted and a new one is recreated, this is effectively "trashing" the old information. But since SCM tools like git treat it as a change to the same file, the changes can be reviewed, and I believe it's important that the file is reviewed (and not just ignore the changes that happen on it).

Grammers has tests to enforce that all dependencies used by the project have some documentation on why they are needed. This makes the process of adding additional dependencies require more thought and rationale, so the number can remain low. I find deterministic builds interesting, but have no personal use for them in my current projects. Since I'm the main owner of the code, I know what the built binary will do (provided I also trust the dependencies to play nice).

For binaries and dependencies intalled with `cargo`, I rely on the automatic checks it performs (if any). It's mostly trust, though.

The dependency tree and final binary size can quickly explode if dependencies are not kept in check, which is why I favor re-implementing parts as needed.

I think `cargo tree` is great at providing a good overview, a well as the aforementioned semver checks. But it would be nice if `cargo-crev` was more popular.

Only as a way to count how many direct and transitive dependencies it has installed in total.

## P9

There was a time, I remember I placed the JS of an open-source comment framework in the A4, this JS contained some key settings, after GitHub scanned it, it was considered to have security vulnerabilities, and the final solution was that I deleted the JS and placed it on a CDN for referencing.

So, generally speaking, when I encounter difficulties in updating the npm version, I go ahead and delete or modify the abnormal parts in the source code.

Because I didn't know that a lock file was needed, you are the first person to raise the issue of the lock file. So far, it seems that the installation and use have been normal for me and other netizens.

I previously mentioned that I am mainly a backend developer, so I haven't paid much attention to npm's lock file.

To be honest, when running locally, I didn't pay much attention to the lock file either; my mind was only focused on getting the project up and running, so I thought it might be automatically generated when building the project.
I usually only use npm install, npm remove, and npm publish commands when developing npm locally.

Better ensure dependencies, my usual approach is to verify them myself first, for example, if A4 can depend on another npm project for automatically generating encrypted articles, I would go ahead with npm install, then see what issues arise, debug them, and after that, I would write a post to inform users that A4 can npm install this feature, allowing everyone to install it themselves.

The guarantee of completeness is all personally verified by me, followed by informing users which packages they can self-install and which features they can extend.

The biggest challenge is when I introduce a software package and find that it is not well compatible with A4, I need to go and debug the solution myself, which is the challenge of precise adaptation to other software packages.

I may first need to learn more about better management solutions, as my current practice process is too primitive, and I need to adapt one by one, and might also learn how some predecessors manage.


## P8

Yeah. So we have very few dependencies because it's always very painful to have many. And the ones we do have are still painful. So like, that is something that I'm actively working towards, like getting rid of the last dependencies, because that's just, it's always annoying to have them. And like, for example, one thing is that we have backwards compatibility until node 12 and node 12 didn't have like a global fetch function. So one main dependency is node fetch, which basically just adds something that all later, like all recent versions of node already have, but it would be a breaking change to drop this because it's a very core feature. So it would kind of like change the API. So we can't drop it. But also the maintainers of that thing have decided to drop support for common JS. So now we can't upgrade their dependency anymore. And we also can't get rid of it. And like, it's just constantly an annoyance. And there's not really much we can do, actually, we will have to do a major version and do breaking changes and throw it out. And so that is kind of the deal for all dependencies. Like there's no, or at least I haven't figured out the general rule, how to fix these things, you just have to understand why do you need it? Do you really need it? And, and then look into the specific issue. We didn't have any security issues so far yet. 

I follow all the changes very closely. It's, I mean, it boils down to about it, but it's not having a good review process. Um, I don't think it has ever happened in the past three and a half years that there was like an unused dependency ever. So we are all very cautious about dependencies and, um, because they're so annoying, everyone's trying very hard to get rid of them. Yeah. Uh, but I do know of other open source projects that don't work that way. They pull in like a million dependencies and they don't really care. Uh, that is not how we work. 

Um, because, uh, so there's a difference between library software, like what I write and then application software, which is actually a executed on servers, like directly as the main application, because when you install the dependencies of your project, then the lock file will basically track. Every single version of the entire dependency tree. Right. But it will disregard any lockfiles of these dependencies. So basically if we were to commit a lockfile, it would be ignored by everyone who uses our library. So there's no point really in adding it. And, uh, uh, even worse, if you do add one, you kind of lock all your dependencies to one specific version. So everyone who works on the project, they all have the same version, but all the libraries, library consumers might deviate from these dependencies. So basically what you're doing is you're not exposing yourself to all the different combinations and all the ways how your dependencies will actually be installed. So basically it is better not to commit a lockfile because then you kind of run into these issues faster. And, uh, yeah, you don't have this false sense of security where you think it's all locked, but in reality, everybody who uses it doesn't lock it. 

Uh, I haven't done very thorough reviews of the dependencies that were added and their dependencies. So I kind of just trusted the people who did the change to do these checks, which probably is not ideal, but, uh, yeah, it, it did not really happen that often. Um, so the, the main dependencies that we, when we integrate with database drivers, then we often need these official database drivers as peer dependencies. And so we kind of just trust them anyways. It's kind of like this, this idea, okay, you install whatever postgres and then integrate with postgres. Then we kind of need postgres too, in order to integrate. But at that point, the application developer already has it installed. So it's not like we are adding anything to the tree. Yeah. And the other, the only other case I remember where somebody added the dependency basically for convenience. Uh, it was actually removed again before the release because we figured it's not worth the, the overhead. So yeah, we don't really do it as much. 

No. Uh, well, okay. So this is a bit special. There are a few places where we do have a package lock file, but it's not a lot of work. lockFile, but it's get ignored. So everybody just has a local version and we don't really know what people use. Um, it might be like, for example, in continuous integration, it's regenerated all the time. Uh, but then again, we don't really use NPM as the primary way of installing dependencies. We have like this, um, hybrid support for both Dino and node. And so like with Dino, you just, uh, we basically disabled the lockfile. So it's just not generated. And then, uh, when we do an NPM publish, it kind of gets created automatically in CI, but you're like, uh, on the core repository, I don't have a lockfile locally. I don't have NPM in there really.

pretty much just trusting it. Uh, yeah. Uh, yeah. It's, it's not ideal, but it's, yeah. No, there's a, there's one thing that's very cool. It's called JSR and I don't know if you've heard about it, uh, but it's kind of like this new thing that tries to replace NPM. Mm-hmm. And what they have is this, uh, security feature where you can, you can build your dependency, like your, like compile it in GitHub actions. Mm-hmm. And it will actually, uh, show, like a verified badge when you download the dependency on JSR. Uh, so it knows that the, the build output hasn't been tampered with. So as long as you depend on JSR and do things only from there, then you can basically automatically get this software bill of materials and know, like have like a verification for every single dependency. That is very cool. We're trying to migrate there, but it's not really that mature yet. Uh, it has very cool features, but it's, it's like, there are a few things that are missing. Um, so the whole security aspect will get a lot better once we move away from NPM. 

I, I wouldn't know exactly. Yeah. Um, so what Dino does is it uses URL imports. So like you just specify the URL of whatever you have. Whatever you want to import in the, in the import statement. And then it just fetches the typescript file from there. Um, so that is also a bit annoying because URLs don't have semantic versioning. Mm-hmm . So you can't really resolve different patch releases. Mm-hmm . So you have to make sure that every dependency in your entire tree specifies the exact same patch version. So, because otherwise you run into this, this diamond problem of where like dependencies are duplicated and that is really annoying. And then we have the service code lip.dino.dev and they basically do like HTTP redirects. And that is all really ugly. Like Dino did not have a good weight of managing dependencies before JSR. Uh, so like, I mean, NPM is bad, but what Dino did at the beginning is like, that is just unacceptable. Like basically they could, instead of redirecting to the dependency we want to have whoever authors lived or Dino to dev, I didn't even know they could serve as arbitrary code. And we just import it and execute it. It's, it's really bad. Um, it'll be fixed. 
Yeah. I mean, I think once you have a working lockfile, it kind of works pretty well. Um, at least like when I think about applications, right. In libraries, I don't really care because it's not really useful to have it. But when I think about the applications I developed, then it like, once you have a lockfile, it works pretty well. What the problems are more that, uh, there's NPM and then there's yarn and then there's PNPM. And they all have different lockfiles that call differently. They're structured differently. And then I think the worst of them all is bun and they use like a binary lockfile, which is the worst idea because now you can't view the diff. Like you, you don't know what's going on and you can't even merge. It's that is like the dumbest idea ever. And, but, but I don't use bun. I don't know. Yeah. And so, but so the, this diversity of tools and they all have the different formats and then, you know, like you use your package manager and then you hop into another project and suddenly it's all different, different lockfiles, different things. Uh, that is more annoying than. Then some intrinsic behavior of how lockfiles work or like how NPM does them or something that usually works pretty much just fine. 

So not really. I mean, I find it interesting to have this opportunity. But I haven't really had a use case for it yet. I do open source and it's MIT license. So people can do whatever they want. And I don't have any warranty or like, it's just, you know, if, if it breaks for them, that's their problem. So I don't really feel like I need to ensure this. But, uh, sure. If you're a company and you want to make sure, you know, what code you're executing, then getting that is really, really useful. And having it built into the registry is like that saves so much time. Yeah. I see the value. 

Uh, I mean, I would sort of assume that an S-BOMS has more like information about it, that it also collects things like licensees and, and I don't know. Uh, but then again, you can technically derive from the S-BOMS. You can, you can technically derive these things from the lockfile too. You just have to like fetch the data for each entry individually. Well, it's probably an interesting idea to make these two equivalent. I don't know. Yeah. Yeah. No, I just wanted to know how you see.
But I mean, the lockfile also contains a list. So it's like, yeah, but it makes sense. Like, because the, the, if you have an S-BOMS, I would expect that there's also like licenses in there and maybe who also authors these packages and perhaps how long they've been updated. If you can link to CVEs. It would make sense to kind of integrate this. And that stuff really doesn't have anything to do with lockfiles. Right. So. It's, it's probably like the use cases are very different. 

There are a few things like, like, I don't know, even if your dependency management is very good, it's still advisable not to have many dependencies. So like, just the fact that other people can break your code. Is kind of annoying. Um, but it's like an inherently hard problem because you also don't want to reinvent the wheel all the time. So I don't, I don't really see any good approaches to improving the situation. Um, yeah, no, I think the short answer is no, not really, unfortunately. 

I think we're more strict with the regular dependencies than we are with dev dependencies. Like if you have a dev dependency and it breaks, then that's kind of annoying, but you can fix it and it won't affect your library consumers. Um, but still the, so what we do as library developers a lot is, uh, somebody reports a bug, we fix it on some branch. And then before we actually merge and release, we tell people, Hey, could you pull from this branch and check in your project? If that fixes your issue, just to confirm like end to end that this actually solved the problem. And so NPM has this feature called GitHub installs where you basically just install directly from a repository and then do like hashtag branch name. So, uh, what NPM does is actually download the repository contents and install all the dev dependencies and the regular dependencies, and then run prepare scripts. So basically we can execute any arbitrary code on developers machines if they do this, um, which is funny, but that's on them. And so, uh, that also means that development dependencies are installed regularly. And some people after we fixed the issue, like, I don't really know if they actually migrate back to a proper release version or if they keep on using the division that they installed from some branch. So that's why dev dependencies do get installed quite regularly on like in different production systems. And so already for that reason, it is still pretty important to make sure you don't have a lot of them. And that the ones you do have are very reliable. For example, we built our own compiler or build chain because we didn't want to use any other. And so we just make sure this one's maintained. And I, I think that's pretty much the only thing that everybody needs. Yeah. There might be, there might be other dependencies that I'm not aware of, but like we are still very careful with them, even though they are probably not as bad as normal dependencies. 

It always like it's, it's interesting because everybody who does software agrees that dependencies are necessary. And also everybody agrees that you don't want them. It's like this necessary evil. And it's somewhat comparable to build systems. They are also very painful and still you need them. And it's weird to me that we haven't come up with a good, like, like everybody who uses any programming language complains about the ways that this language manages dependencies. And I don't know. It's, it always kind of makes me a bit sad or triggers me to be like, Oh, this is annoying. We have to like do dependencies again. So, so that's, I don't know what you want to do with this observation, but it's just something that I noticed. 

Yeah. I do notice too, that a lot of people commit their lockfiles and I'm always like, yeah, but you're doing a library. This makes no sense. Like it's, do you know, it's making things worse? 

I don't know. I look into shrink-wrap. I've used it four years ago and then for some reason I decided that it's not worth it or that it's doing something that I didn't want to do but I forgot what it does. 
